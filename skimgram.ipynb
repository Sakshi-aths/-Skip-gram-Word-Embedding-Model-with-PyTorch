{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 326.5692\n",
      "Epoch 2/100, Loss: 240.5756\n",
      "Epoch 3/100, Loss: 221.9105\n",
      "Epoch 4/100, Loss: 210.2976\n",
      "Epoch 5/100, Loss: 208.9994\n",
      "Epoch 6/100, Loss: 203.8143\n",
      "Epoch 7/100, Loss: 199.3090\n",
      "Epoch 8/100, Loss: 193.3830\n",
      "Epoch 9/100, Loss: 189.8686\n",
      "Epoch 10/100, Loss: 189.0976\n",
      "Epoch 11/100, Loss: 187.1076\n",
      "Epoch 12/100, Loss: 183.1389\n",
      "Epoch 13/100, Loss: 188.2026\n",
      "Epoch 14/100, Loss: 182.0420\n",
      "Epoch 15/100, Loss: 180.2733\n",
      "Epoch 16/100, Loss: 184.4121\n",
      "Epoch 17/100, Loss: 177.8322\n",
      "Epoch 18/100, Loss: 177.3433\n",
      "Epoch 19/100, Loss: 175.0189\n",
      "Epoch 20/100, Loss: 172.9039\n",
      "Epoch 21/100, Loss: 174.6234\n",
      "Epoch 22/100, Loss: 170.9439\n",
      "Epoch 23/100, Loss: 173.5810\n",
      "Epoch 24/100, Loss: 171.8322\n",
      "Epoch 25/100, Loss: 170.2956\n",
      "Epoch 26/100, Loss: 169.7782\n",
      "Epoch 27/100, Loss: 169.3074\n",
      "Epoch 28/100, Loss: 164.6531\n",
      "Epoch 29/100, Loss: 164.5360\n",
      "Epoch 30/100, Loss: 164.9567\n",
      "Epoch 31/100, Loss: 165.6603\n",
      "Epoch 32/100, Loss: 168.7977\n",
      "Epoch 33/100, Loss: 166.8100\n",
      "Epoch 34/100, Loss: 169.9723\n",
      "Epoch 35/100, Loss: 167.2809\n",
      "Epoch 36/100, Loss: 162.4117\n",
      "Epoch 37/100, Loss: 164.9513\n",
      "Epoch 38/100, Loss: 163.6328\n",
      "Epoch 39/100, Loss: 164.9408\n",
      "Epoch 40/100, Loss: 165.1496\n",
      "Epoch 41/100, Loss: 161.3909\n",
      "Epoch 42/100, Loss: 161.4332\n",
      "Epoch 43/100, Loss: 162.0572\n",
      "Epoch 44/100, Loss: 162.6760\n",
      "Epoch 45/100, Loss: 162.0560\n",
      "Epoch 46/100, Loss: 163.3670\n",
      "Epoch 47/100, Loss: 161.5535\n",
      "Epoch 48/100, Loss: 159.4791\n",
      "Epoch 49/100, Loss: 160.1829\n",
      "Epoch 50/100, Loss: 161.2020\n",
      "Epoch 51/100, Loss: 159.6618\n",
      "Epoch 52/100, Loss: 158.4586\n",
      "Epoch 53/100, Loss: 162.0452\n",
      "Epoch 54/100, Loss: 165.1097\n",
      "Epoch 55/100, Loss: 162.6176\n",
      "Epoch 56/100, Loss: 159.9004\n",
      "Epoch 57/100, Loss: 158.8654\n",
      "Epoch 58/100, Loss: 157.9918\n",
      "Epoch 59/100, Loss: 159.1790\n",
      "Epoch 60/100, Loss: 159.2525\n",
      "Epoch 61/100, Loss: 160.3150\n",
      "Epoch 62/100, Loss: 157.7256\n",
      "Epoch 63/100, Loss: 159.0888\n",
      "Epoch 64/100, Loss: 159.4541\n",
      "Epoch 65/100, Loss: 157.4810\n",
      "Epoch 66/100, Loss: 155.7890\n",
      "Epoch 67/100, Loss: 158.6907\n",
      "Epoch 68/100, Loss: 157.2184\n",
      "Epoch 69/100, Loss: 158.9276\n",
      "Epoch 70/100, Loss: 156.0794\n",
      "Epoch 71/100, Loss: 156.7031\n",
      "Epoch 72/100, Loss: 157.8266\n",
      "Epoch 73/100, Loss: 157.8077\n",
      "Epoch 74/100, Loss: 156.3443\n",
      "Epoch 75/100, Loss: 157.1362\n",
      "Epoch 76/100, Loss: 157.2303\n",
      "Epoch 77/100, Loss: 156.5472\n",
      "Epoch 78/100, Loss: 157.8538\n",
      "Epoch 79/100, Loss: 153.6925\n",
      "Epoch 80/100, Loss: 156.3682\n",
      "Epoch 81/100, Loss: 154.6454\n",
      "Epoch 82/100, Loss: 154.9843\n",
      "Epoch 83/100, Loss: 156.4194\n",
      "Epoch 84/100, Loss: 155.6762\n",
      "Epoch 85/100, Loss: 157.2374\n",
      "Epoch 86/100, Loss: 154.2986\n",
      "Epoch 87/100, Loss: 157.5920\n",
      "Epoch 88/100, Loss: 153.5113\n",
      "Epoch 89/100, Loss: 156.1712\n",
      "Epoch 90/100, Loss: 156.1594\n",
      "Epoch 91/100, Loss: 153.4678\n",
      "Epoch 92/100, Loss: 155.4590\n",
      "Epoch 93/100, Loss: 153.7709\n",
      "Epoch 94/100, Loss: 154.9291\n",
      "Epoch 95/100, Loss: 153.3559\n",
      "Epoch 96/100, Loss: 152.8279\n",
      "Epoch 97/100, Loss: 152.8404\n",
      "Epoch 98/100, Loss: 152.4796\n",
      "Epoch 99/100, Loss: 153.1302\n",
      "Epoch 100/100, Loss: 153.4784\n",
      "\n",
      "Word Embeddings (example words):\n",
      "nlp: [ 0.01482187  0.0051661  -0.09484238 -0.06845076 -0.59162235  0.08213751\n",
      "  0.04608135  2.4552863   0.05315121 -0.5275992   0.00872013  0.06115909\n",
      " -0.00668643  0.0101108  -0.27090985  0.4090911   0.03798927 -0.05337608\n",
      " -0.7890985   0.09556019  1.7030145  -0.00996894 -0.01071748  0.236465\n",
      " -0.37989905 -0.28941584  0.01348012 -0.56404084 -0.02008723 -0.04441998\n",
      " -0.14394648  1.1746446   0.00992738 -0.0621222   0.06472751  0.16214976\n",
      " -0.27674004 -0.0194463  -0.04517071  0.06819685 -0.06048235 -0.7595074\n",
      " -0.03633176 -0.1431289  -0.01495287 -0.01356275 -0.02659342  0.04674138\n",
      " -0.03997146 -0.01553402]\n",
      "embeddings: [-0.0345677   0.01187392 -0.02428545  0.01020487  0.24959524 -0.7358814\n",
      "  0.00717928 -0.4031964  -0.05854825 -0.01926057  0.01588789  0.04763867\n",
      "  0.1018317   0.04006854 -0.12290282  0.8664109  -0.01755856  0.23642933\n",
      "  0.33968678 -0.6001069   0.01106106 -0.04119102 -0.146188    0.00199548\n",
      " -0.7687387   1.1120218  -0.094304    0.7794007  -0.18324366  0.08429559\n",
      "  0.28972837 -0.18446974  0.02892939 -0.05080239 -1.0907307  -0.04668814\n",
      "  0.04676248 -0.0113919   0.083056   -0.213027   -0.01911727 -0.57526386\n",
      "  0.00795408 -0.17024617  0.27157766 -0.01257382 -0.35847446 -0.04779807\n",
      " -0.02396571  0.00853023]\n",
      "vector: [ 8.4029706e-03 -2.8554294e-01 -4.5099296e-03 -1.0553298e-03\n",
      "  1.4151841e+00 -6.3275963e-01 -2.3128282e-01 -2.5170025e-01\n",
      " -1.3752531e-02  2.9617254e-02  9.0803048e-03  1.5280677e-02\n",
      " -4.6066791e-03  1.8162722e-02  1.7695668e-01 -1.3609452e-03\n",
      " -2.1545777e-04  2.6688363e-02  1.3113217e-01 -3.1390342e-01\n",
      "  2.8249148e-02  4.6055245e-01 -8.4024556e-03  2.3637868e-02\n",
      " -8.4584057e-01 -7.3086783e-02 -1.2092510e-02 -3.8048294e-01\n",
      " -6.8505488e-02 -5.0001144e-03 -2.7194208e-02 -9.0462551e-02\n",
      "  5.2700621e-01  5.8412729e-03  1.2368402e+00 -5.6888860e-01\n",
      "  1.0897043e-01 -3.5844002e-02  1.5751254e-02 -1.8348210e-01\n",
      "  2.2929979e-02  2.9807213e-01 -6.7003682e-02 -2.7126802e-02\n",
      " -1.0085496e+00  4.5306930e-01 -3.3272404e-02  3.4395146e-01\n",
      " -9.1838390e-02 -1.4880039e-02]\n",
      "deep: [ 4.7041427e-02  4.7234032e-02  1.2888244e+00  6.7383133e-02\n",
      " -5.3533965e-01 -2.6249465e-02 -1.6047481e-02  1.3549136e-01\n",
      "  1.0489907e-01  6.4980894e-02  3.5792064e-02 -4.2992670e-02\n",
      "  2.3176783e-01  6.5426506e-02 -1.6043793e+00 -8.0765374e-02\n",
      " -8.4799014e-02  4.4711539e-01  7.5573526e-02  4.2223427e-02\n",
      " -5.9009284e-01  2.2148006e-01  4.9521598e-01 -2.8696632e-01\n",
      "  1.8183424e-01  1.7701194e-01 -4.7480482e-01 -4.9109630e-02\n",
      "  5.7640672e-01 -3.3934247e-02 -4.9306896e-02  1.5350285e-01\n",
      "  2.5418910e-01 -1.2580361e+00 -3.2503746e-02  7.4227810e-02\n",
      "  3.1492400e-01  2.3640466e-01  5.6936687e-01 -5.0316453e-02\n",
      "  7.2122878e-01  5.8309388e-01  1.6973469e+00  3.4784622e-02\n",
      " -9.1936272e-01 -1.5516131e-02 -8.2543336e-02  3.0327495e-04\n",
      " -1.2488456e-01  6.9095656e-02]\n",
      "processing: [ 0.00592823  0.03892929  0.3412132   0.5376888   1.1893395   0.04682948\n",
      "  0.06103328  0.0865984  -0.0202646   0.02388264 -0.00460195 -0.01607306\n",
      "  0.06026367  0.03017547 -0.09023551 -0.01623926 -0.01829488 -0.04653872\n",
      "  0.0263754   0.04961581 -0.01927456  1.1370023   0.04510705 -0.49084106\n",
      "  0.29447755  0.02160506  0.01022183 -0.0093213  -0.64059854 -0.00685901\n",
      "  0.02422219  0.07051356 -0.01825049 -1.0052388  -0.00644992  0.16088626\n",
      " -0.85292757 -0.3795266   0.09898435 -0.03685686 -0.3199586   0.77395517\n",
      "  0.69516987 -0.00591593 -0.00759    -0.02794142 -0.05848052  0.00267727\n",
      "  0.6504851   0.02435466]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Prepare a small corpus for training\n",
    "corpus = [\n",
    "    \"natural language processing is amazing\",\n",
    "    \"deep learning is a key area of artificial intelligence\",\n",
    "    \"word embeddings represent words in vector space\",\n",
    "    \"embeddings are the foundation of modern nlp\",\n",
    "]\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
    "\n",
    "# Create a vocabulary and assign an index to each word\n",
    "vocab = list(set(chain(*tokenized_corpus)))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Step 2: Generate training data for the Skip-gram model\n",
    "def generate_training_data(tokenized_corpus, window_size=2):\n",
    "    training_data = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        for i, target_word in enumerate(sentence):\n",
    "            start = max(i - window_size, 0)\n",
    "            end = min(i + window_size + 1, len(sentence))\n",
    "            context_words = [sentence[j] for j in range(start, end) if j != i]\n",
    "            for context_word in context_words:\n",
    "                training_data.append((target_word, context_word))\n",
    "    return training_data\n",
    "\n",
    "training_data = generate_training_data(tokenized_corpus)\n",
    "\n",
    "# Step 3: Define the Skip-gram model\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, target_word_idx):\n",
    "        # Look up embeddings for the target word\n",
    "        target_embedding = self.embedding(target_word_idx)\n",
    "        # Project the embedding to the vocabulary size\n",
    "        output = self.output_layer(target_embedding)\n",
    "        return output\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 50\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Initialize the Skip-gram model\n",
    "model = SkipGramModel(vocab_size, embedding_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 4: Training the Skip-gram model\n",
    "def word_to_tensor(word):\n",
    "    return torch.tensor([word_to_idx[word]], dtype=torch.long)\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    random.shuffle(training_data)  # Shuffle training data each epoch\n",
    "    for target_word, context_word in training_data:\n",
    "        optimizer.zero_grad()\n",
    "        target_tensor = word_to_tensor(target_word)\n",
    "        context_idx = word_to_idx[context_word]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(target_tensor)\n",
    "        loss = criterion(output, torch.tensor([context_idx]))\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Step 5: Visualizing word embeddings\n",
    "def get_word_embedding(word):\n",
    "    with torch.no_grad():\n",
    "        word_idx = word_to_tensor(word)\n",
    "        return model.embedding(word_idx).numpy().squeeze()\n",
    "\n",
    "# Visualize a few word embeddings\n",
    "print(\"\\nWord Embeddings (example words):\")\n",
    "for word in [\"nlp\", \"embeddings\", \"vector\", \"deep\", \"processing\"]:\n",
    "    if word in word_to_idx:\n",
    "        print(f\"{word}: {get_word_embedding(word)}\")\n",
    "\n",
    "# Optional: Save the embeddings for later use\n",
    "np.save(\"word_embeddings.npy\", model.embedding.weight.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
